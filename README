## Concurrent HTTP Proxy Server

A multithreaded HTTP proxy server that forwards client requests to web servers and returns responses. Handles multiple concurrent connections using POSIX threads and implements robust error handling for network failures.

### Features

**Concurrent Request Handling**
- Thread-per-request model using pthreads
- Detached threads for automatic resource cleanup
- Non-blocking concurrent client serving

**HTTP Protocol Implementation**
- GET request forwarding and parsing
- HTTP/1.0 compliance
- Custom User-Agent header injection
- Full header preservation and forwarding

**Robust Error Handling**
- Malformed request detection (400 Bad Request)
- Unsupported method handling (501 Not Implemented)
- Server connection failures (503 Service Unavailable)
- SIGPIPE blocking to prevent crashes on broken connections

**Network Communication**
- Client-proxy-server connection management
- Proper socket lifecycle (accept, forward, close)
- Bidirectional data streaming with `rio` buffered I/O

### Usage
```bash
# Compile
make

# Run the proxy on port 8080
./proxy 8080

# Configure browser or use curl
curl -x http://localhost:8080 http://example.com
```

### Architecture
```
Client → Proxy (accept) → Parse request → Forward to server
                ↓
         Spawn thread for each client
                ↓
Server → Proxy (receive) → Forward response → Client
```

**Request Flow:**
1. Accept client connection on listening socket
2. Spawn detached thread to handle request
3. Parse HTTP request line and headers
4. Open connection to target server
5. Forward modified request (with proxy User-Agent)
6. Stream response back to client
7. Clean up resources and exit thread

### Implementation Highlights

**Thread Management**
```c
pthread_t tid;
pthread_create(&tid, NULL, serve, client);
// Thread detaches itself for automatic cleanup
pthread_detach(pthread_self());
```

**HTTP Request Parsing**
- Uses custom parser to validate request format
- Preserves all client headers except User-Agent
- Adds HTTP/1.0 compliance headers
- Validates minimum header requirements

**Signal Handling**
```c
// Block SIGPIPE to prevent crashes on broken pipes
sigset_t mask;
sigemptyset(&mask);
sigaddset(&mask, SIGPIPE);
sigprocmask(SIG_BLOCK, &mask, NULL);
```

**Buffered I/O**
- Rio (Robust I/O) library for reliable reading/writing
- Handles partial reads/writes automatically
- Buffer management for efficient data transfer

### Error Responses

The proxy sends proper HTTP error responses:
- **400 Bad Request**: Malformed HTTP request
- **501 Not Implemented**: Non-GET methods
- **503 Service Unavailable**: Cannot reach target server

### Technical Challenges Solved

1. **Concurrent Connections**: Pthreads enable serving multiple clients simultaneously without blocking

2. **Resource Management**: Detached threads automatically clean up; proper socket closure prevents leaks

3. **Protocol Compliance**: Correct HTTP/1.0 request formatting with required headers

4. **Broken Pipe Handling**: SIGPIPE blocking prevents proxy crashes when clients disconnect unexpectedly

### Limitations

- No caching (could add LRU cache for frequently accessed objects)
- HTTP/1.0 only (no persistent connections)
- GET requests only (no POST, PUT, etc.)
- No HTTPS/TLS support
- No request/response modification beyond User-Agent

### Performance Considerations

- Thread-per-request model scales to hundreds of concurrent clients
- Detached threads eliminate need for explicit joining
- Buffered I/O reduces system call overhead
- Could be extended with thread pooling for higher loads

### Testing

Tested with:
- Standard web browsers (Firefox, Chrome)
- Command-line tools (curl, wget)
- Concurrent load testing
- Malformed request handling
- Server timeout scenarios

### Possible Extensions

- **Caching**: Implement LRU cache for 100KB objects (up to 1MB total)
- **HTTPS**: Add TLS/SSL support with OpenSSL
- **Logging**: Request/response logging and statistics
- **Content Filtering**: URL blocking or content inspection
- **Load Balancing**: Distribute requests across multiple backend servers
